The Heston stochastic volatility model remains a cornerstone of modern quantitative finance, offering a more realistic framework for pricing European options than its constant-volatility predecessors by capturing empirical features such as volatility clustering and the volatility smile \parencite{heston1993}. The calibration of the Heston model, the process of inferring its unobservable parameters from market option prices, is a critical task for risk management and the pricing of exotic derivatives. This process, however, constitutes a non-trivial inverse problem characterized by a high-dimensional, non-convex error surface. Traditional calibration methods, which rely on repeatedly evaluating the model's semi-analytical pricing formula within an optimization loop, are computationally intensive and sensitive to the choice of initial parameters \parencite{escobar2016parametersrecoverycalibrationhestonmodel}, making them challenging to deploy in settings that require real-time recalibration.

In recent years, deep learning has emerged as a promising alternative to address the dual challenges of computational efficiency and calibration accuracy. The literature has explored several distinct approaches. One prominent method involves training a neural network as a surrogate model to approximate the complex mapping from model parameters and option characteristics to a final option price. This replaces the slow numerical pricing engine with a fast neural network inference \parencite{liu2019neuralnetworkbasedframeworkfinancialmodelcalibration}. A related technique employs a two-stage hybrid framework, where one network approximates the market price surface and a second network learns to correct the systematic residual errors of a traditionally calibrated Heston model \parencite{zadgar2025deeplearningenhancedcalibrationheston}. A third paradigm formulates calibration as an inverse mapping problem, training a network to learn the direct mapping from market observables, such as an asset's historical time series, to the underlying Heston parameters \parencite{leite2021deeponetsfinanceapproachcalibratehestonmodel}. While innovative, this latter approach addresses the problem of parameter estimation from historical paths rather than the industry-standard problem of calibration to a cross-section of current market option prices.

An advancement in this field is the development of \ac{ddn}, which are trained using a Sobolev-style \parencite{czarnecki2017sobolevtrainingneuralnetworks} loss function to learn not only the option price but also its partial derivatives with respect to the model parameters \parencite{zhang2025calibratinghestonmodeldeep}. By embedding this structural information, \ac{ddn}s can serve as highly accurate pricing engines for fast, gradient-based calibration routines. However, the performance of these advanced frameworks, including \ac{ddn}s, has primarily been evaluated on static datasets or under controlled conditions. A comprehensive validation of their longitudinal robustness, generalization capabilities on large and complex real-world option surfaces, and stability across diverse market and macroeconomic regimes remains an open area of investigation.

This study aims to fill this gap by conducting a rigorous, multi-year historical backtest of a \ac{ddn}-based calibration methodology. We employ a \ac{ddn} not as a standalone calibrator, but as a high-speed, high-fidelity surrogate pricing engine within a classical quasi-Newton optimization framework (L-BFGS-B, \textcite{byrd1995limitedmemoryalgorithmboundconstrainedoptimization}). This hybrid approach is systematically evaluated through a comprehensive longitudinal backtest on a large dataset of \ac{aapl} option prices from 2016 to 2023. The framework incorporates practical adaptations for real-world data, including a dynamic, daily estimation of the market-implied risk-free rate derived from put-call parity.

Specifically, this research seeks to answer several key questions. First, how robust is the calibration accuracy of the \ac{ddn}-based Heston model when applied longitudinally over a multi-year period that encompasses diverse market regimes, including periods of low volatility, market crashes, and changing interest rate environments? Second, to what extent does the methodology generalize from the in-sample (calibration) set to an out-of-sample (test) set on a daily basis, and is there evidence of significant overfitting when fitting to a large cross-section of options? Finally, what is the quantitative relationship between calibration error and realized market volatility, and does the methodology's accuracy degrade or become unstable during periods of extreme market stress?