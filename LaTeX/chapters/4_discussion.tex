The results of this study indicate that a \ac{ddn}, when employed as a surrogate pricing engine within a classical optimization framework, represents a robust and accurate methodology for calibrating the Heston stochastic volatility model. The findings provide direct answers to the primary research questions posed. In response to the question of longitudinal robustness, the methodology demonstrates considerable stability across the seven-year backtest period from 2016 to 2023. A quantitative analysis indicate a direct, positive correlation between calibration error and realized market volatility. During periods of acute market stress, such as the COVID-19 crash in March 2020, the out-of-sample \ac{mre} reached a maximum observed level of approximately 14\%. However, this degradation was not a sign of model instability; the error remained bounded and consistently reverted to its baseline level below 5\% as market volatility subsided, confirming the framework's resilience.

Regarding the question of generalization on real-world data, the \ac{ddn} calibration methodology generalizes effectively from the in-sample calibration set to the held-out test set on a daily basis. The minimal observed gap between the average in-sample \ac{mre} of 5.33\% and the average out-of-sample \ac{mre} of 5.55\% provides strong empirical evidence that the model does not suffer from significant overfitting. This holds true even when fitting to a large and complex cross-section of options, which averaged 261 unique contracts per day. Furthermore, in response to the question of adaptability, the calibration performance shows no systematic failure or bias related to the prevailing macroeconomic environment. The model remains stable across the entire observed spectrum of market-implied interest rates, including periods of near-zero and negative rates. The weak negative correlation detected between calibration error and the implied risk-free rate appears to be a confounding effect of market volatility, which often coincides with low-rate environments, rather than a direct causal relationship.

These findings both validate and extend the foundational work of \textcite{zhang2025calibratinghestonmodeldeep}, confirming that \ac{ddn}s are potent tools for Heston calibration, but on a more challenging and practical scale. While our average out-of-sample \ac{mre} of 5.55\% is numerically higher than the 4.64\% reported in the reference study for a 100-option dataset, our result was achieved on a calibration surface that was, on average, 2.6 times larger and more complex. The performance degradation as the number of options increases, noted in the foundational paper, suggests our approach demonstrates superior scalability to real-world conditions. Methodological enhancements were critical to achieving this robustness in a longitudinal backtest. The use of a quasi-Newton optimizer (L-BFGS-B) provided more stable convergence than a first-order method, and the dynamic, daily calculation of a market-implied interest rate via put-call parity was essential for adapting the model to changing dividend yields and rate regimes.

The success of the framework can be attributed to the synergistic combination of its core mechanisms. The practice of Sobolev training, which penalizes errors in both the option price and its partial derivatives, is the key mechanism that enforces the geometric structure of the pricing surface, thereby preventing overfitting and enabling the strong generalization observed. This high-fidelity surrogate model, trained to a validation loss of approximately $2.09 \times 10^{-5}$ using an AdamW optimizer and a Cosine Decay with Restarts learning rate schedule, is sufficiently precise to guide the final L-BFGS-B optimizer to an accurate minimum. Finally, the incorporation of financial constraints, such as the use of log-moneyness as an input to enforce model homogeneity and a softplus activation function on the output layer to guarantee positive option prices, contributes significantly to the model's stability across diverse market conditions.

From a practical standpoint, this hybrid approach offers a viable solution to the long-standing trade-off between calibration speed and accuracy in quantitative finance. The sub-second calibration time per day, achieved through a multi-start scheme, makes the methodology suitable for applications requiring frequent recalibration, such as intra-day risk management or the valuation of large derivatives portfolios. However, several limitations must be acknowledged. The \ac{ddn}'s accuracy is fundamentally bounded by the fidelity of the \texttt{QuantLib} library used to generate its synthetic training data; it will faithfully replicate any numerical biases of its source. Moreover, the framework is designed to find the optimal Heston parameters, but it cannot address the underlying issue of Heston model misspecification. The observed increase in calibration error during market stress is likely a reflection of the Heston model's own limitations in capturing extreme dynamics. Finally, the error analysis revealed a significantly higher \ac{mre} for \ac{otm} put options, which is a direct consequence of error propagation through the put-call parity formula when small absolute errors on expensive calls are translated into large relative errors on cheap puts.

These limitations suggest several directions for future research. The \ac{ddn} surrogate approach is particularly promising for models that lack semi-analytical pricing solutions, such as those incorporating jumps or rough volatility, where a network could be trained on data from computationally intensive Monte Carlo simulations to create a fast and accurate pricer. The methodology could also be extended to learn the pricing surfaces and sensitivities of exotic, path-dependent derivatives. Furthermore, to address the heteroscedasticity of option prices and the error propagation observed in \ac{otm} contracts, future iterations of the model could be trained directly on the implied volatility surface rather than raw prices. In conjunction with this, implementing a Vega-weighted loss function would allow the optimization process to prioritize contracts with higher sensitivity to volatility, thereby aligning the calibration metric more closely with market risk management priorities. Finally, replacing the deterministic network with a Bayesian Neural Network or a deep ensemble could allow the model to provide not only a point estimate for price but also a credible interval, offering a quantitative measure of model uncertainty valuable for risk management.